#!/usr/bin/env node

/**
 * Test script for regional inference and model restriction removal
 * Run this after starting the backend to test the new functionality
 */

const API_BASE = 'http://localhost:8080';

async function testModelRestrictionRemoval() {
  console.log('üß™ Testing Model Restriction Removal...\n');
  
  // Test 1: OpenAI with newer model
  console.log('1. Testing OpenAI with newer model pattern...');
  try {
    const response = await fetch(`${API_BASE}/api/public/models?provider=openai`, {
      headers: {
        'x-api-key': 'sk-test-key-for-validation'
      }
    });
    
    if (response.status === 400) {
      console.log('‚úÖ OpenAI validation working (expected 400 for test key)');
    } else {
      console.log('‚ùì Unexpected response:', response.status);
    }
  } catch (error) {
    console.log('‚ùå Error:', error.message);
  }
  
  // Test 2: Bedrock with non-Anthropic model
  console.log('\n2. Testing Bedrock model validation...');
  try {
    const response = await fetch(`${API_BASE}/api/public/models?provider=bedrock`, {
      headers: {
        'x-aws-access-key-id': 'AKIATEST',
        'x-aws-secret-access-key': 'test-secret',
        'x-aws-region': 'us-east-1'
      }
    });
    
    if (response.status === 400) {
      console.log('‚úÖ Bedrock validation working (expected 400 for test credentials)');
    } else {
      console.log('‚ùì Unexpected response:', response.status);
    }
  } catch (error) {
    console.log('‚ùå Error:', error.message);
  }
}

async function testRegionalInference() {
  console.log('\nüåç Testing Regional Inference Support...\n');
  
  // Test 1: Regional inference with auto-generated endpoint
  console.log('1. Testing regional inference with auto-generated endpoint...');
  try {
    const response = await fetch(`${API_BASE}/api/public/models?provider=bedrock`, {
      headers: {
        'x-aws-access-key-id': 'AKIATEST',
        'x-aws-secret-access-key': 'test-secret',
        'x-aws-region': 'eu-west-1',
        'x-use-regional-inference': 'true'
      }
    });
    
    if (response.status === 400) {
      console.log('‚úÖ Regional inference parameter accepted (expected 400 for test credentials)');
    } else {
      console.log('‚ùì Unexpected response:', response.status);
    }
  } catch (error) {
    console.log('‚ùå Error:', error.message);
  }
  
  // Test 2: Regional inference with custom endpoint
  console.log('\n2. Testing regional inference with custom endpoint...');
  try {
    const response = await fetch(`${API_BASE}/api/public/models?provider=bedrock`, {
      headers: {
        'x-aws-access-key-id': 'AKIATEST',
        'x-aws-secret-access-key': 'test-secret',
        'x-aws-region': 'ap-southeast-1',
        'x-use-regional-inference': 'true',
        'x-regional-inference-endpoint': 'https://bedrock-runtime.ap-southeast-1.amazonaws.com'
      }
    });
    
    if (response.status === 400) {
      console.log('‚úÖ Custom regional endpoint parameter accepted (expected 400 for test credentials)');
    } else {
      console.log('‚ùì Unexpected response:', response.status);
    }
  } catch (error) {
    console.log('‚ùå Error:', error.message);
  }
}

async function testModelSupport() {
  console.log('\nü§ñ Testing Enhanced Model Support...\n');
  
  // Test model detection
  const testModels = [
    // OpenAI models
    { model: 'gpt-4-turbo-2024-04-09', expectedProvider: 'openai' },
    { model: 'gpt-3.5-turbo-16k', expectedProvider: 'openai' },
    { model: 'o1-preview-2024-09-12', expectedProvider: 'openai' },
    
    // Bedrock models
    { model: 'anthropic.claude-3-5-sonnet-20241022-v2:0', expectedProvider: 'bedrock' },
    { model: 'amazon.titan-text-express-v1', expectedProvider: 'bedrock' },
    { model: 'ai21.j2-ultra-v1', expectedProvider: 'bedrock' },
    { model: 'cohere.command-text-v14', expectedProvider: 'bedrock' },
    { model: 'meta.llama2-70b-chat-v1', expectedProvider: 'bedrock' },
  ];
  
  console.log('Testing model provider detection...');
  
  // This would require importing the LLM service, so we'll just log the test cases
  testModels.forEach(({ model, expectedProvider }) => {
    console.log(`  ${model} ‚Üí ${expectedProvider}`);
  });
  
  console.log('‚úÖ Model patterns defined for testing');
}

async function runTests() {
  console.log('üöÄ CatalAIst Regional Inference & Model Support Tests\n');
  console.log('=' .repeat(60));
  
  await testModelRestrictionRemoval();
  await testRegionalInference();
  await testModelSupport();
  
  console.log('\n' + '=' .repeat(60));
  console.log('‚ú® Tests completed!');
  console.log('\nüìù Notes:');
  console.log('- 400 responses are expected for test credentials');
  console.log('- For full testing, use real AWS credentials and OpenAI API keys');
  console.log('- Check backend logs for detailed regional inference endpoint usage');
  console.log('- Test the frontend UI for regional inference configuration');
}

// Run tests if this script is executed directly
if (require.main === module) {
  runTests().catch(console.error);
}

module.exports = {
  testModelRestrictionRemoval,
  testRegionalInference,
  testModelSupport,
  runTests
};