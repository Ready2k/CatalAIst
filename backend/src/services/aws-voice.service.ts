import {
  BedrockRuntimeClient,
  InvokeModelWithResponseStreamCommand,
} from '@aws-sdk/client-bedrock-runtime';
import { NodeHttpHandler } from '@aws-sdk/node-http-handler';
import https from 'https';
import { Readable } from 'stream';
import { v4 as uuidv4 } from 'uuid';
import { LLMProviderConfig } from './llm-provider.interface';

/**
 * AWS Voice Service - Nova 2 Sonic Bidirectional Streaming
 * 
 * This service provides real-time conversational AI using Amazon Nova 2 Sonic's
 * bidirectional streaming capabilities for speech-to-speech interaction.
 * 
 * Features:
 * - Real-time speech input and output
 * - No S3 storage required (privacy-first)
 * - Natural conversation flow with turn-taking
 * - Multilingual support with automatic detection
 */
export class AWSVoiceService {
  private readonly TIMEOUT_MS = 30000; // 30 seconds
  private readonly MAX_RETRIES = 3;
  private readonly INITIAL_RETRY_DELAY_MS = 1000; // 1 second
  private readonly NOVA_SONIC_MODEL_ID = 'amazon.nova-2-sonic-v1:0';
  private readonly NOVA_SONIC_V1_MODEL_ID = 'amazon.nova-sonic-v1:0'; // Fallback option

  /**
   * Start a conversational session with Nova 2 Sonic
   * This replaces the traditional transcribe method with real-time streaming
   */
  async startConversation(
    config: LLMProviderConfig,
    systemPrompt?: string
  ): Promise<{
    sessionId: string;
    streamingEndpoint: string;
  }> {
    const sessionId = uuidv4();

    // For now, return session info - we'll implement WebSocket streaming next
    return {
      sessionId,
      streamingEndpoint: `/api/voice/stream/${sessionId}`
    };
  }

  /**
   * Process audio input through Nova 2 Sonic using Converse API
   * This provides speech-to-speech functionality
   */
  async processAudioStream(
    audioStream: Readable,
    config: LLMProviderConfig,
    systemPrompt?: string
  ): Promise<{ transcription: string; response: string; audioResponse?: Buffer }> {
    return this.withRetry(async () => {
      const bedrockClient = this.createBedrockClient(config);

      // Convert audio stream to base64 for Nova 2 Sonic
      const audioBuffer = await this.streamToBuffer(audioStream);
      const audioBase64 = audioBuffer.toString('base64');

      console.log('[Nova 2 Sonic] Processing speech-to-speech conversation...');

      try {
        // Try using Converse API first (may not work with audio input)
        const command = new InvokeModelWithResponseStreamCommand({
          modelId: this.NOVA_SONIC_MODEL_ID,
          contentType: 'application/json',
          accept: 'application/json',
          body: JSON.stringify({
            messages: [
              {
                role: 'user',
                content: [
                  {
                    type: 'audio',
                    source: {
                      type: 'base64',
                      media_type: 'audio/wav',
                      data: audioBase64
                    }
                  }
                ]
              }
            ],
            system: [
              {
                text: systemPrompt || this.getDefaultSystemPrompt()
              }
            ],
            inferenceConfig: {
              maxTokens: 1024,
              temperature: 0.7,
              topP: 0.9
            },
            additionalModelRequestFields: {
              audio: {
                format: 'mp3'
              }
            }
          })
        });

        const response = await bedrockClient.send(command);

        if (!response.body) {
          throw new Error('No response body from Nova 2 Sonic');
        }

        // Process the streaming response
        let transcription = '';
        let textResponse = '';
        let audioData: Buffer | undefined;

        for await (const chunk of response.body) {
          if (chunk.chunk?.bytes) {
            const chunkData = JSON.parse(new TextDecoder().decode(chunk.chunk.bytes));

            // Extract transcription if available
            if (chunkData.inputTranscript) {
              transcription = chunkData.inputTranscript;
            }

            // Extract text response
            if (chunkData.message?.content) {
              for (const content of chunkData.message.content) {
                if (content.text) {
                  textResponse += content.text;
                }
                // Extract audio data if available
                if (content.audio?.data) {
                  audioData = Buffer.from(content.audio.data, 'base64');
                }
              }
            }
          }
        }

        return {
          transcription: transcription || 'Speech processed by Nova 2 Sonic',
          response: textResponse || 'Response generated by Nova 2 Sonic',
          audioResponse: audioData
        };

      } catch (error) {
        console.error('[Nova 2 Sonic] Error processing audio:', error);

        // Provide helpful error messages for common Nova 2 Sonic issues
        if (error instanceof Error) {
          if (error.message.includes('ValidationException') && error.message.includes('model ID is not supported')) {
            const region = config.awsRegion || 'us-east-1';
            const supportedRegions = ['us-east-1', 'us-west-2', 'ap-northeast-1', 'eu-north-1'];
            return {
              transcription: 'Region not supported',
              response: `Nova 2 Sonic is not available in region '${region}'. Supported regions: ${supportedRegions.join(', ')}. Please change your AWS region in the configuration.`,
              audioResponse: undefined
            };
          }

          if (error.message.includes('AccessDeniedException')) {
            return {
              transcription: 'Access denied',
              response: 'Access denied to Nova 2 Sonic. Please ensure you have the required IAM permissions and that Nova 2 Sonic access has been granted to your AWS account.',
              audioResponse: undefined
            };
          }
        }

        // For now, return a helpful message indicating the limitation
        return {
          transcription: 'Audio input received',
          response: 'Nova 2 Sonic requires bidirectional streaming API for full speech-to-speech functionality. This feature is currently being implemented.',
          audioResponse: undefined
        };
      }
    });
  }

  /**
   * Synthesize speech using Nova 2 Sonic (fallback for text-only requests)
   */
  /**
   * Synthesize speech using Nova 2 Sonic (via bidirectional stream)
   */
  async synthesize(
    text: string,
    voice: string,
    config: LLMProviderConfig
  ): Promise<Buffer> {
    console.log('[Nova 2 Sonic] Synthesizing speech from text (bidirectional stream)... START');
    const { InvokeModelWithBidirectionalStreamCommand } = await import('@aws-sdk/client-bedrock-runtime');
    const bedrockClient = this.createBedrockClient(config);

    try {
      const sessionId = uuidv4();
      const promptName = uuidv4();
      const contentName = uuidv4();
      const silenceContentId = uuidv4();
      const systemContentId = uuidv4();
      const effectiveVoiceId = (voice === 'nova-sonic' || !voice) ? 'ruth' : voice;

      // Queued events to establish session and request speech
      const eventsQueue = [
        // 1. Session Start
        {
          sessionStart: {
            inferenceConfiguration: {
              maxTokens: 1024,
              topP: 0.9,
              temperature: 0.7
            }
          }
        },
        // 2. Prompt Start
        {
          promptStart: {
            promptName,
            textOutputConfiguration: { mediaType: 'text/plain' },
            audioOutputConfiguration: {
              audioType: 'SPEECH',
              encoding: 'base64',
              mediaType: 'audio/lpcm',
              sampleRateHertz: 24000,
              sampleSizeBits: 16,
              channelCount: 1,
              voiceId: effectiveVoiceId
            }
          }
        },
        // 3. System Prompt
        {
          contentStart: {
            promptName,
            contentName: systemContentId,
            type: 'TEXT',
            interactive: false,
            role: 'SYSTEM',
            textInputConfiguration: { mediaType: 'text/plain' }
          }
        },
        {
          textInput: {
            promptName,
            contentName: systemContentId,
            content: `You are a text-to-speech engine. Please read the user's input aloud exactly as written, word for word. Do not answer questions. Do not add any introductory text.`
          }
        },
        {
          contentEnd: {
            promptName,
            contentName: systemContentId
          }
        },
        // 4. Start Audio Context (Interactive - Mimic Streaming Open)
        {
          contentStart: {
            promptName,
            contentName: silenceContentId,
            type: 'AUDIO',
            role: 'USER',
            interactive: true,
            audioInputConfiguration: {
              audioType: 'SPEECH',
              encoding: 'base64',
              mediaType: 'audio/lpcm',
              sampleRateHertz: 16000,
              sampleSizeBits: 16,
              channelCount: 1
            }
          }
        },
        // Inject 1s Silence
        {
          audioInput: {
            promptName,
            contentName: silenceContentId,
            content: Buffer.alloc(32000, 0).toString('base64')
          }
        },
        // DO NOT END AUDIO YET - Keep open while sending text

        // 5. User Text (Sent while audio stream is "active")
        {
          contentStart: {
            promptName,
            contentName,
            type: 'TEXT',
            role: 'USER',
            interactive: true,
            textInputConfiguration: { mediaType: 'text/plain' }
          }
        },
        {
          textInput: {
            promptName,
            contentName,
            content: `Role: Interviewer - ask the following text in a professional way\nText: "${text}"\nDO NOT ask any more questions and DO NOT expect a response`
          }
        },
        {
          contentEnd: {
            promptName,
            contentName
          }
        },

        // 6. NOW End Audio (Signal end of user turn audio)
        {
          contentEnd: {
            promptName,
            contentName: silenceContentId
          }
        },

        // 7. Prompt End
        {
          promptEnd: {
            promptName
          }
        }
      ];

      // Generator for input stream (Fixes AsyncIterable usage)
      async function* eventGenerator() {
        for (const event of eventsQueue) {
          // Nova 2 Sonic expects the event object to be wrapped in a 'chunk' property
          // with 'bytes' containing the JSON stringified event.
          yield {
            chunk: {
              bytes: new TextEncoder().encode(JSON.stringify({ event }))
            }
          };
        }
      }

      console.log(`[Nova 2 Sonic] Sending ${eventsQueue.length} events...`);

      const response = await bedrockClient.send(new InvokeModelWithBidirectionalStreamCommand({
        modelId: 'amazon.nova-2-sonic-v1:0',
        body: eventGenerator()
      }));

      if (!response.body) {
        throw new Error('No response body from Nova 2 Sonic');
      }

      const audioChunks: Buffer[] = [];

      for await (const chunk of response.body) {
        if (chunk.chunk && chunk.chunk.bytes) {
          const textDecoder = new TextDecoder('utf-8');
          const textData = textDecoder.decode(chunk.chunk.bytes);

          try {
            const jsonEvent = JSON.parse(textData);

            if (jsonEvent.event?.audioOutput) {
              const audioBase64 = jsonEvent.event.audioOutput.content || jsonEvent.event.audioOutput;
              const audioBuffer = Buffer.from(audioBase64, 'base64');
              audioChunks.push(audioBuffer);
            } else if (jsonEvent.event?.textOutput) {
              console.log(`[Nova 2 Sonic] Text Output: ${JSON.stringify(jsonEvent.event.textOutput)}`);
            } else if (jsonEvent.modelStreamErrorException || jsonEvent.internalServerException) {
              console.error(`[Nova 2 Sonic] Error Event:`, jsonEvent);
            }
          } catch (e) {
            // Ignore non-JSON chunks or malformed JSON
          }
        }
      }

      if (audioChunks.length === 0) {
        console.warn('[Nova 2 Sonic] No audio data received, returning empty buffer');
        return Buffer.alloc(0);
      }

      const pcmBuffer = Buffer.concat(audioChunks);

      // Create WAV Header
      const header = Buffer.alloc(44);
      header.write('RIFF', 0);
      header.writeUInt32LE(36 + pcmBuffer.length, 4);
      header.write('WAVE', 8);
      header.write('fmt ', 12);
      header.writeUInt32LE(16, 16);
      header.writeUInt16LE(1, 20);
      header.writeUInt16LE(1, 22);
      header.writeUInt32LE(24000, 24);
      header.writeUInt32LE(24000 * 1 * 2, 28);
      header.writeUInt16LE(2, 32);
      header.writeUInt16LE(16, 34);
      header.write('data', 36);
      header.writeUInt32LE(pcmBuffer.length, 40);

      return Buffer.concat([header, pcmBuffer]);

    } catch (error: any) {
      console.error('[Nova 2 Sonic] Error synthesizing speech:', error);
      return Buffer.alloc(0);
    }
  }

  /**
   * Map voice names to Nova 2 Sonic voice options
   */
  private mapVoiceToNovaSonic(voice: string): string {
    const voiceMap: Record<string, string> = {
      'nova-sonic': 'nova-sonic',
      'sonic': 'nova-sonic',
      'nova': 'nova-sonic',
      'ruth': 'nova-sonic',
      // Map other voices to Nova 2 Sonic as default
      'alloy': 'nova-sonic',
      'echo': 'nova-sonic',
      'fable': 'nova-sonic',
      'onyx': 'nova-sonic',
      'shimmer': 'nova-sonic',
      'joanna': 'nova-sonic',
      'matthew': 'nova-sonic',
      'amy': 'nova-sonic',
      'brian': 'nova-sonic',
      'emma': 'nova-sonic',
    };

    return voiceMap[voice.toLowerCase()] || 'nova-sonic';
  }

  /**
   * Get default system prompt for Nova 2 Sonic conversations
   */
  private getDefaultSystemPrompt(): string {
    return `You are a warm, professional, and helpful AI assistant. Give accurate answers that sound natural, direct, and human. Start by answering the user's question clearly in 1–2 sentences. Then, expand only enough to make the answer understandable, staying within 3–5 short sentences total. Avoid sounding like a lecture or essay.`;
  }

  /**
   * Create Bedrock client for Nova 2 Sonic
   */
  private createBedrockClient(config: LLMProviderConfig): BedrockRuntimeClient {
    if (!config.awsAccessKeyId || !config.awsSecretAccessKey) {
      throw new Error('AWS credentials are required for Nova 2 Sonic');
    }

    const clientConfig: any = {
      region: config.awsRegion || 'us-east-1',
      credentials: {
        accessKeyId: config.awsAccessKeyId,
        secretAccessKey: config.awsSecretAccessKey,
      },
    };

    if (config.awsSessionToken) {
      clientConfig.credentials.sessionToken = config.awsSessionToken;
    }

    // Handle self-signed certificates
    const rejectUnauthorized = process.env.NODE_TLS_REJECT_UNAUTHORIZED !== '0';

    if (!rejectUnauthorized) {
      const httpsAgent = new https.Agent({
        rejectUnauthorized: false,
        keepAlive: true,
      });

      clientConfig.requestHandler = new NodeHttpHandler({
        httpsAgent,
        connectionTimeout: 30000,
        socketTimeout: 30000,
      });
    }

    return new BedrockRuntimeClient(clientConfig);
  }

  /**
   * Convert stream to buffer
   */
  private async streamToBuffer(stream: Readable): Promise<Buffer> {
    const chunks: Buffer[] = [];

    return new Promise((resolve, reject) => {
      stream.on('data', (chunk) => chunks.push(chunk));
      stream.on('error', reject);
      stream.on('end', () => resolve(Buffer.concat(chunks)));
    });
  }

  /**
   * Retry logic with exponential backoff
   */
  private async withRetry<T>(
    operation: () => Promise<T>,
    attempt: number = 1
  ): Promise<T> {
    try {
      return await operation();
    } catch (error) {
      if (attempt >= this.MAX_RETRIES) {
        throw error;
      }

      // Check if error is retryable
      if (this.isRetryableError(error)) {
        const delay = this.INITIAL_RETRY_DELAY_MS * Math.pow(2, attempt - 1);
        await this.sleep(delay);
        return this.withRetry(operation, attempt + 1);
      }

      throw error;
    }
  }

  /**
   * Timeout wrapper for promises
   */
  private async withTimeout<T>(
    promise: Promise<T>,
    timeoutMs: number
  ): Promise<T> {
    return Promise.race([
      promise,
      new Promise<T>((_, reject) =>
        setTimeout(
          () => reject(new Error(`Operation timed out after ${timeoutMs}ms`)),
          timeoutMs
        )
      ),
    ]);
  }

  /**
   * Check if error is retryable
   */
  private isRetryableError(error: any): boolean {
    // Retry on throttling and server errors
    if (error?.name === 'ThrottlingException') {
      return true;
    }

    if (error?.$metadata?.httpStatusCode) {
      const status = error.$metadata.httpStatusCode;
      return status === 429 || status >= 500;
    }

    // Retry on timeout errors
    if (error?.message?.includes('timeout')) {
      return true;
    }

    // Retry on network errors
    if (error?.code === 'ECONNRESET' || error?.code === 'ETIMEDOUT') {
      return true;
    }

    return false;
  }

  /**
   * Sleep utility
   */
  private sleep(ms: number): Promise<void> {
    return new Promise((resolve) => setTimeout(resolve, ms));
  }

  /**
   * Legacy transcribe method - now redirects to Nova 2 Sonic processing
   */
  async transcribe(
    audioStream: Readable,
    config: LLMProviderConfig
  ): Promise<{ transcription: string; duration: number }> {
    console.log('[Nova 2 Sonic] Using speech-to-speech processing instead of separate transcription');

    const result = await this.processAudioStream(audioStream, config);

    return {
      transcription: result.transcription,
      duration: 0 // Duration not applicable for streaming conversations
    };
  }
}