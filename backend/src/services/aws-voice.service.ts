import {
  BedrockRuntimeClient,
  InvokeModelWithResponseStreamCommand,
} from '@aws-sdk/client-bedrock-runtime';
import { NodeHttpHandler } from '@aws-sdk/node-http-handler';
import https from 'https';
import { Readable } from 'stream';
import { v4 as uuidv4 } from 'uuid';
import { LLMProviderConfig } from './llm-provider.interface';

/**
 * AWS Voice Service - Nova 2 Sonic Bidirectional Streaming
 * 
 * This service provides real-time conversational AI using Amazon Nova 2 Sonic's
 * bidirectional streaming capabilities for speech-to-speech interaction.
 * 
 * Features:
 * - Real-time speech input and output
 * - No S3 storage required (privacy-first)
 * - Natural conversation flow with turn-taking
 * - Multilingual support with automatic detection
 */
export class AWSVoiceService {
  private readonly TIMEOUT_MS = 30000; // 30 seconds
  private readonly MAX_RETRIES = 3;
  private readonly INITIAL_RETRY_DELAY_MS = 1000; // 1 second
  private readonly NOVA_SONIC_MODEL_ID = 'amazon.nova-2-sonic-v1:0';
  private readonly NOVA_SONIC_V1_MODEL_ID = 'amazon.nova-sonic-v1:0'; // Fallback option

  /**
   * Start a conversational session with Nova 2 Sonic
   * This replaces the traditional transcribe method with real-time streaming
   */
  async startConversation(
    config: LLMProviderConfig,
    systemPrompt?: string
  ): Promise<{
    sessionId: string;
    streamingEndpoint: string;
  }> {
    const sessionId = uuidv4();

    // For now, return session info - we'll implement WebSocket streaming next
    return {
      sessionId,
      streamingEndpoint: `/api/voice/stream/${sessionId}`
    };
  }

  /**
   * Process audio input through Nova 2 Sonic using Converse API
   * This provides speech-to-speech functionality
   */
  async processAudioStream(
    audioStream: Readable,
    config: LLMProviderConfig,
    systemPrompt?: string
  ): Promise<{ transcription: string; response: string; audioResponse?: Buffer }> {
    return this.withRetry(async () => {
      const bedrockClient = this.createBedrockClient(config);

      // Convert audio stream to base64 for Nova 2 Sonic
      const audioBuffer = await this.streamToBuffer(audioStream);
      const audioBase64 = audioBuffer.toString('base64');

      console.log('[Nova 2 Sonic] Processing speech-to-speech conversation...');

      try {
        // Try using Converse API first (may not work with audio input)
        const command = new InvokeModelWithResponseStreamCommand({
          modelId: this.NOVA_SONIC_MODEL_ID,
          contentType: 'application/json',
          accept: 'application/json',
          body: JSON.stringify({
            messages: [
              {
                role: 'user',
                content: [
                  {
                    type: 'audio',
                    source: {
                      type: 'base64',
                      media_type: 'audio/wav',
                      data: audioBase64
                    }
                  }
                ]
              }
            ],
            system: [
              {
                text: systemPrompt || this.getDefaultSystemPrompt()
              }
            ],
            inferenceConfig: {
              maxTokens: 1024,
              temperature: 0.7,
              topP: 0.9
            },
            additionalModelRequestFields: {
              audio: {
                format: 'mp3'
              }
            }
          })
        });

        const response = await bedrockClient.send(command);

        if (!response.body) {
          throw new Error('No response body from Nova 2 Sonic');
        }

        // Process the streaming response
        let transcription = '';
        let textResponse = '';
        let audioData: Buffer | undefined;

        for await (const chunk of response.body) {
          if (chunk.chunk?.bytes) {
            const chunkData = JSON.parse(new TextDecoder().decode(chunk.chunk.bytes));

            // Extract transcription if available
            if (chunkData.inputTranscript) {
              transcription = chunkData.inputTranscript;
            }

            // Extract text response
            if (chunkData.message?.content) {
              for (const content of chunkData.message.content) {
                if (content.text) {
                  textResponse += content.text;
                }
                // Extract audio data if available
                if (content.audio?.data) {
                  audioData = Buffer.from(content.audio.data, 'base64');
                }
              }
            }
          }
        }

        return {
          transcription: transcription || 'Speech processed by Nova 2 Sonic',
          response: textResponse || 'Response generated by Nova 2 Sonic',
          audioResponse: audioData
        };

      } catch (error) {
        console.error('[Nova 2 Sonic] Error processing audio:', error);

        // Provide helpful error messages for common Nova 2 Sonic issues
        if (error instanceof Error) {
          if (error.message.includes('ValidationException') && error.message.includes('model ID is not supported')) {
            const region = config.awsRegion || 'us-east-1';
            const supportedRegions = ['us-east-1', 'us-west-2', 'ap-northeast-1', 'eu-north-1'];
            return {
              transcription: 'Region not supported',
              response: `Nova 2 Sonic is not available in region '${region}'. Supported regions: ${supportedRegions.join(', ')}. Please change your AWS region in the configuration.`,
              audioResponse: undefined
            };
          }

          if (error.message.includes('AccessDeniedException')) {
            return {
              transcription: 'Access denied',
              response: 'Access denied to Nova 2 Sonic. Please ensure you have the required IAM permissions and that Nova 2 Sonic access has been granted to your AWS account.',
              audioResponse: undefined
            };
          }
        }

        // For now, return a helpful message indicating the limitation
        return {
          transcription: 'Audio input received',
          response: 'Nova 2 Sonic requires bidirectional streaming API for full speech-to-speech functionality. This feature is currently being implemented.',
          audioResponse: undefined
        };
      }
    });
  }

  /**
   * Synthesize speech using Nova 2 Sonic (fallback for text-only requests)
   */
  /**
   * Synthesize speech using Nova 2 Sonic (via bidirectional stream)
   */
  async synthesize(
    text: string,
    voice: string,
    config: LLMProviderConfig
  ): Promise<Buffer> {
    const { InvokeModelWithBidirectionalStreamCommand } = await import('@aws-sdk/client-bedrock-runtime');

    return this.withRetry(async () => {
      const bedrockClient = this.createBedrockClient(config);

      console.log('[Nova 2 Sonic] Synthesizing speech from text (bidirectional stream)...');

      try {
        const sessionId = uuidv4();
        const promptName = uuidv4();
        const contentName = uuidv4();

        // Queued events to establish session and request speech
        const eventsQueue = [
          // 1. Session Start
          {
            sessionStart: {
              inferenceConfiguration: { maxTokens: 1024 }
            }
          },
          // 2. Prompt Start - configuration including audio format
          {
            promptStart: {
              promptName,
              textOutputConfiguration: { mediaType: 'text/plain' },
              audioOutputConfiguration: {
                audioType: 'SPEECH',
                mediaType: 'audio/mpeg', // Request MP3 directly
                encoding: 'base64',
                sampleRateHertz: 24000
              }
            }
          },
          // 3. Content Start
          {
            contentStart: {
              promptName,
              contentName,
              type: 'TEXT',
              role: 'USER'
            }
          },
          // 4. Text Input
          {
            textInput: {
              promptName,
              contentName,
              content: text
            }
          },
          // 5. Content End
          {
            contentEnd: {
              promptName,
              contentName
            }
          }
        ];

        // Create async iterator for input stream
        const asyncIterable: any = {
          [Symbol.asyncIterator]: () => {
            let index = 0;
            return {
              next: async () => {
                if (index >= eventsQueue.length) {
                  return { value: undefined, done: true };
                }
                const event = eventsQueue[index++];

                return {
                  value: {
                    chunk: {
                      bytes: new TextEncoder().encode(JSON.stringify(event))
                    }
                  },
                  done: false
                };
              }
            };
          }
        };

        const command = new InvokeModelWithBidirectionalStreamCommand({
          modelId: this.NOVA_SONIC_MODEL_ID,
          body: asyncIterable,
        });

        const response = await bedrockClient.send(command);

        if (!response.body) {
          throw new Error('No response body from Nova 2 Sonic');
        }

        // Process the streaming response to extract audio
        const audioChunks: Buffer[] = [];

        for await (const event of response.body) {
          if (event.chunk?.bytes) {
            try {
              const chunkData = JSON.parse(new TextDecoder().decode(event.chunk.bytes));

              const audioBase64 = chunkData.event?.audioOutput?.content || chunkData.event?.audioOutput;
              if (audioBase64) {
                audioChunks.push(Buffer.from(audioBase64, 'base64'));
              }
            } catch (e) {
              // Ignore parse errors for partial chunks
            }
          }
        }

        if (audioChunks.length === 0) {
          console.warn('[Nova 2 Sonic] No audio data received, returning empty buffer');
          return Buffer.alloc(0);
        }

        return Buffer.concat(audioChunks);

      } catch (error) {
        console.error('[Nova 2 Sonic] Error synthesizing speech:', error);
        console.warn('[Nova 2 Sonic] Returning empty buffer due to synthesis error');
        return Buffer.alloc(0);
      }
    });
  }

  /**
   * Map voice names to Nova 2 Sonic voice options
   */
  private mapVoiceToNovaSonic(voice: string): string {
    const voiceMap: Record<string, string> = {
      'nova-sonic': 'nova-sonic',
      'sonic': 'nova-sonic',
      'nova': 'nova-sonic',
      'ruth': 'nova-sonic',
      // Map other voices to Nova 2 Sonic as default
      'alloy': 'nova-sonic',
      'echo': 'nova-sonic',
      'fable': 'nova-sonic',
      'onyx': 'nova-sonic',
      'shimmer': 'nova-sonic',
      'joanna': 'nova-sonic',
      'matthew': 'nova-sonic',
      'amy': 'nova-sonic',
      'brian': 'nova-sonic',
      'emma': 'nova-sonic',
    };

    return voiceMap[voice.toLowerCase()] || 'nova-sonic';
  }

  /**
   * Get default system prompt for Nova 2 Sonic conversations
   */
  private getDefaultSystemPrompt(): string {
    return `You are a warm, professional, and helpful AI assistant. Give accurate answers that sound natural, direct, and human. Start by answering the user's question clearly in 1–2 sentences. Then, expand only enough to make the answer understandable, staying within 3–5 short sentences total. Avoid sounding like a lecture or essay.`;
  }

  /**
   * Create Bedrock client for Nova 2 Sonic
   */
  private createBedrockClient(config: LLMProviderConfig): BedrockRuntimeClient {
    if (!config.awsAccessKeyId || !config.awsSecretAccessKey) {
      throw new Error('AWS credentials are required for Nova 2 Sonic');
    }

    const clientConfig: any = {
      region: config.awsRegion || 'us-east-1',
      credentials: {
        accessKeyId: config.awsAccessKeyId,
        secretAccessKey: config.awsSecretAccessKey,
      },
    };

    if (config.awsSessionToken) {
      clientConfig.credentials.sessionToken = config.awsSessionToken;
    }

    // Handle self-signed certificates
    const rejectUnauthorized = process.env.NODE_TLS_REJECT_UNAUTHORIZED !== '0';

    if (!rejectUnauthorized) {
      const httpsAgent = new https.Agent({
        rejectUnauthorized: false,
        keepAlive: true,
      });

      clientConfig.requestHandler = new NodeHttpHandler({
        httpsAgent,
        connectionTimeout: 30000,
        socketTimeout: 30000,
      });
    }

    return new BedrockRuntimeClient(clientConfig);
  }

  /**
   * Convert stream to buffer
   */
  private async streamToBuffer(stream: Readable): Promise<Buffer> {
    const chunks: Buffer[] = [];

    return new Promise((resolve, reject) => {
      stream.on('data', (chunk) => chunks.push(chunk));
      stream.on('error', reject);
      stream.on('end', () => resolve(Buffer.concat(chunks)));
    });
  }

  /**
   * Retry logic with exponential backoff
   */
  private async withRetry<T>(
    operation: () => Promise<T>,
    attempt: number = 1
  ): Promise<T> {
    try {
      return await operation();
    } catch (error) {
      if (attempt >= this.MAX_RETRIES) {
        throw error;
      }

      // Check if error is retryable
      if (this.isRetryableError(error)) {
        const delay = this.INITIAL_RETRY_DELAY_MS * Math.pow(2, attempt - 1);
        await this.sleep(delay);
        return this.withRetry(operation, attempt + 1);
      }

      throw error;
    }
  }

  /**
   * Timeout wrapper for promises
   */
  private async withTimeout<T>(
    promise: Promise<T>,
    timeoutMs: number
  ): Promise<T> {
    return Promise.race([
      promise,
      new Promise<T>((_, reject) =>
        setTimeout(
          () => reject(new Error(`Operation timed out after ${timeoutMs}ms`)),
          timeoutMs
        )
      ),
    ]);
  }

  /**
   * Check if error is retryable
   */
  private isRetryableError(error: any): boolean {
    // Retry on throttling and server errors
    if (error?.name === 'ThrottlingException') {
      return true;
    }

    if (error?.$metadata?.httpStatusCode) {
      const status = error.$metadata.httpStatusCode;
      return status === 429 || status >= 500;
    }

    // Retry on timeout errors
    if (error?.message?.includes('timeout')) {
      return true;
    }

    // Retry on network errors
    if (error?.code === 'ECONNRESET' || error?.code === 'ETIMEDOUT') {
      return true;
    }

    return false;
  }

  /**
   * Sleep utility
   */
  private sleep(ms: number): Promise<void> {
    return new Promise((resolve) => setTimeout(resolve, ms));
  }

  /**
   * Legacy transcribe method - now redirects to Nova 2 Sonic processing
   */
  async transcribe(
    audioStream: Readable,
    config: LLMProviderConfig
  ): Promise<{ transcription: string; duration: number }> {
    console.log('[Nova 2 Sonic] Using speech-to-speech processing instead of separate transcription');

    const result = await this.processAudioStream(audioStream, config);

    return {
      transcription: result.transcription,
      duration: 0 // Duration not applicable for streaming conversations
    };
  }
}